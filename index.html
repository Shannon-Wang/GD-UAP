---
---

<div class="post-header-home">
  <h1 class="post-title-home">
    <center>Generalizable Data-free Objective for Crafting Universal Adversarial Perturbations</center>
  </h1>
  <div data-purplecoat="shiori" data-purplecoat-label="post-header-home.html">
    <center><h2><p class="text-muted">Konda Reddy Mopuri*, Aditya Ganeshan*, R. Venkatesh Babu (* = equal contribution)</p></h2></center>
      <center><h3><p class="text-muted">Video Analytics Lab, CDS</p></h3></center>
        <center><h3><p class="text-muted">Indian Institute of Science, Bangalore</p></h3></center>
  </div>

</div>
<div class="post-content">
  <div class="well well-sm">
    T. B. A. a small Web GL algorithm representation.
  </div>
    <h1 >
      Abstract
  </h1>
  <p>Machine learning models are susceptible to adversarial perturbations: small changes to input that can cause large changes
in output. It is also demonstrated that there exist input-agnostic perturbations, called universal adversarial perturbations, which can
change the inference of target model on most of the data samples. However, existing methods to craft universal perturbations are (i)
task specific, (ii) require samples from the training data distribution, and (iii) perform complex optimizations. Also, because of the data
dependence, fooling ability of the crafted perturbations is proportional to the available training data. In this paper, we present a novel,
generalizable and data-free objective for crafting universal adversarial perturbations. Independent of the underlying task, our objective
achieves fooling via corrupting the extracted features at multiple layers. Therefore, the proposed objective is generalizable to craft
image-agnostic perturbations across multiple vision tasks such as object recognition, semantic segmentation and depth estimation.
In the practical setting of black-box attacking scenario, we show that our objective outperforms the data dependent objectives to fool
the learned models. Further, via exploiting simple priors related to the data distribution, our objective remarkably boosts the fooling
ability of the crafted perturbations. Significant fooling rates achieved by our objective emphasize that the current deep learning models
are now at an increased risk, since our objective generalizes across multiple tasks without the requirement of training data for crafting
the perturbations. To encourage reproducible research, we have released the code for our proposed algorithm at <a href="https://github.com/val-iisc/GD-UAP" target="_blank">GitHub</a>.
  </p>
  <h1> Paper </h1>
  <p>
    
  <div class="well">
<img src="pdf_0.jpg" alt="Mountain View" style="width:100%">
<img src="pdf_2.jpg" alt="Mountain View" style="width:100%">
<img src="pdf_3.jpg" alt="Mountain View" style="width:66.66%">
      </div>
    Arxiv Link: <a href= "https://arxiv.org/abs/1801.08092" target= '_blank'>https://arxiv.org/abs/1801.08092</a>
  </p>
  <h1> BibTex </h1>
  <p>
    <div class="well well-sm">
      @article{gduap-mopuri-2018,<br>
  title={Generalizable Data-free Objective for Crafting Universal Adversarial<br>
    Perturbations},<br>
  author={Mopuri, Konda Reddy and Ganeshan, Aditya and Babu, R Venkatesh},<br>
  booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)},<br>
  year = {2018}<br>
  }<br>
  </div>
  </code>
  </p>
  <h1> Code Provided at <a href="https://github.com/val-iisc/GD-UAP" target="_blank">GitHub</a>.


</div>

<hr>
